#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ UX –¥–∞–Ω–Ω—ã—Ö
"""

import json
import re
import time
import numpy as np
from typing import List, Dict, Any, Optional, Union
from dataclasses import dataclass, field
from tqdm import tqdm

from .openrouter_client import OpenRouterClient
from .brief_manager import BriefManager
from .data_models import InterviewSummary, ResearchFindings

@dataclass
class AnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞"""
    interview_summaries: List[InterviewSummary] = field(default_factory=list)
    research_findings: Optional[ResearchFindings] = None
    total_interviews: int = 0
    analysis_duration: float = 0.0
    api_calls: int = 0
    total_cost: float = 0.0

class OpenRouterAnalyzer:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenRouter API"""
    
    def __init__(self, api_key: str, model: str = "anthropic/claude-3.5-sonnet"):
        self.client = OpenRouterClient(api_key, model)
        self.brief_manager = BriefManager()
        self.analysis_config = {
            'chunk_size': 8000,
            'chunk_overlap': 1000,
            'min_quote_length': 50,
            'max_retries': 3
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.api_calls = 0
        self.total_cost = 0.0
    
    def set_brief(self, brief_content: str) -> bool:
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –±—Ä–∏—Ñ–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"""
        return self.brief_manager.load_brief(brief_content)
    
    def test_api_connection(self) -> bool:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ API"""
        print("üîå –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ OpenRouter API...")
        success = self.client.test_connection()
        if success:
            print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ!")
            model_info = self.client.get_model_info()
            if "error" not in model_info:
                print(f"üìä –ú–æ–¥–µ–ª—å: {model_info.get('name', 'Claude 3.5 Sonnet')}")
                print(f"üìè –ö–æ–Ω—Ç–µ–∫—Å—Ç: {model_info.get('context_length', 'N/A')} —Ç–æ–∫–µ–Ω–æ–≤")
        else:
            print("‚ùå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å!")
        return success
    
    def analyze_transcripts(self, transcripts: List[str]) -> AnalysisResult:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤"""
        start_time = time.time()
        
        print(f"üß† –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ {len(transcripts)} —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤...")
        
        if not self.test_api_connection():
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ API")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏–Ω—Ç–µ—Ä–≤—å—é
        if len(transcripts) < 3:
            print(f"‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 3 –∏–Ω—Ç–µ—Ä–≤—å—é –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞!")
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤—å—é
        interview_summaries = []
        for i, transcript in enumerate(tqdm(transcripts, desc="–ê–Ω–∞–ª–∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é")):
            print(f"\nüìù –ê–Ω–∞–ª–∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é {i+1}/{len(transcripts)}...")
            summary = self._deep_analyze_interview(transcript, i+1)
            interview_summaries.append(summary)
        
        # –ö—Ä–æ—Å—Å-–∞–Ω–∞–ª–∏–∑
        print("\nüîç –ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –∫—Ä–æ—Å—Å-–∞–Ω–∞–ª–∏–∑–∞...")
        cross_analysis = self._cross_analyze_interviews(interview_summaries)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –≤—ã–≤–æ–¥–æ–≤
        print("\nüìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –≤—ã–≤–æ–¥–æ–≤...")
        findings = self._generate_final_findings(interview_summaries, cross_analysis)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result = AnalysisResult(
            interview_summaries=interview_summaries,
            research_findings=findings,
            total_interviews=len(transcripts),
            analysis_duration=time.time() - start_time,
            api_calls=self.api_calls,
            total_cost=self.total_cost
        )
        
        print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {result.analysis_duration:.1f} —Å–µ–∫")
        print(f"üì° API –≤—ã–∑–æ–≤–æ–≤: {self.api_calls}")
        print(f"üí∞ –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ${self.total_cost:.4f}")
        
        return result
    
    def analyze_transcripts_parallel(self, transcripts: List[str]) -> AnalysisResult:
        """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤"""
        start_time = time.time()
        
        print(f"üß† –ù–∞—á–∏–Ω–∞—é –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ {len(transcripts)} —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤...")
        
        if not self.test_api_connection():
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ API")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏–Ω—Ç–µ—Ä–≤—å—é
        if len(transcripts) < 3:
            print(f"‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 3 –∏–Ω—Ç–µ—Ä–≤—å—é –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞!")
        
        # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–±–µ–∑ ThreadPoolExecutor –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è)
        interview_summaries = []
        for i, transcript in enumerate(tqdm(transcripts, desc="–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")):
            print(f"\nüìù –ê–Ω–∞–ª–∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é {i+1}/{len(transcripts)}...")
            summary = self._deep_analyze_interview(transcript, i+1)
            interview_summaries.append(summary)
        
        # –ö—Ä–æ—Å—Å-–∞–Ω–∞–ª–∏–∑
        print("\nüîç –ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –∫—Ä–æ—Å—Å-–∞–Ω–∞–ª–∏–∑–∞...")
        cross_analysis = self._cross_analyze_interviews(interview_summaries)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –≤—ã–≤–æ–¥–æ–≤
        print("\nüìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –≤—ã–≤–æ–¥–æ–≤...")
        findings = self._generate_final_findings(interview_summaries, cross_analysis)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result = AnalysisResult(
            interview_summaries=interview_summaries,
            research_findings=findings,
            total_interviews=len(transcripts),
            analysis_duration=time.time() - start_time,
            api_calls=self.api_calls,
            total_cost=self.total_cost
        )
        
        print(f"\n‚úÖ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {result.analysis_duration:.1f} —Å–µ–∫")
        print(f"üì° API –≤—ã–∑–æ–≤–æ–≤: {self.api_calls}")
        print(f"üí∞ –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ${self.total_cost:.4f}")
        
        return result
    
    def _deep_analyze_interview(self, transcript: str, interview_num: int) -> InterviewSummary:
        """–ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤—å—é"""
        
        # –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏
        chunks = self._create_chunks(transcript)
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞
        chunk_summaries = []
        for i, chunk in enumerate(chunks):
            if len(chunks) > 1:
                print(f"   –ê–Ω–∞–ª–∏–∑ —á–∞—Å—Ç–∏ {i+1}/{len(chunks)}...")
            
            summary = self._analyze_chunk(chunk, interview_num, i+1)
            if summary:
                chunk_summaries.append(summary)
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        combined_summary = "\n\n".join(chunk_summaries)
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        profile_analysis = self._analyze_profile_and_themes(combined_summary, interview_num)
        pains_analysis = self._analyze_pains_and_needs(combined_summary, interview_num)
        emotions_analysis = self._analyze_emotions_and_insights(combined_summary, interview_num)
        quotes_analysis = self._analyze_quotes_and_contradictions(combined_summary, interview_num)
        business_analysis = self._analyze_business_aspects(combined_summary, interview_num)
        
        # –ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–∞–Ω–Ω—ã–π —Å –±—Ä–∏—Ñ–æ–º
        brief_findings = {}
        if self.brief_manager.has_brief:
            brief_findings = self._analyze_brief_related_content(combined_summary, interview_num)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Å–∞–º–º–∞—Ä–∏
        summary_data = {
            'interview_id': interview_num,
            'respondent_profile': profile_analysis.get('respondent_profile', {}),
            'key_themes': profile_analysis.get('key_themes', []),
            'pain_points': pains_analysis.get('pain_points', []),
            'needs': pains_analysis.get('needs', []),
            'insights': emotions_analysis.get('insights', []),
            'emotional_journey': emotions_analysis.get('emotional_journey', []),
            'contradictions': quotes_analysis.get('contradictions', []),
            'quotes': quotes_analysis.get('quotes', []),
            'business_pains': business_analysis.get('business_pains', []),
            'user_problems': business_analysis.get('user_problems', []),
            'opportunities': business_analysis.get('opportunities', []),
            'sentiment_score': emotions_analysis.get('sentiment_score', 0.0),
            'brief_related_findings': brief_findings
        }
        
        return InterviewSummary(**summary_data)
    
    def _create_chunks(self, text: str) -> List[str]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        if len(text) <= self.analysis_config['chunk_size']:
            return [text]
        
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + self.analysis_config['chunk_size']
            chunk = text[start:end]
            chunks.append(chunk)
            start += self.analysis_config['chunk_size'] - self.analysis_config['chunk_overlap']
        
        return chunks
    
    def _analyze_chunk(self, chunk: str, interview_num: int, chunk_num: int) -> str:
        """–ê–Ω–∞–ª–∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —á–∞–Ω–∫–∞"""
        context = self.brief_manager.get_brief_context()
        
        prompt = f"""{context}

–¢—ã ‚Äî –≤–µ–¥—É—â–∏–π UX-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∏–Ω—Ç–µ—Ä–≤—å—é –∏ –∏–∑–≤–ª–µ–∫–∏ –í–°–Æ —Ü–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:
1. –°–æ—Ö—Ä–∞–Ω–∏ –í–°–ï –≤–∞–∂–Ω—ã–µ —Ü–∏—Ç–∞—Ç—ã –ü–û–õ–ù–û–°–¢–¨–Æ –∏ –î–û–°–õ–û–í–ù–û (–º–∏–Ω–∏–º—É–º 50 —Å–ª–æ–≤)
2. –ù–ï –æ–±–æ–±—â–∞–π –∏ –ù–ï –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π - –∫–æ–ø–∏—Ä—É–π —Ç–æ—á–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏
3. –§–∏–∫—Å–∏—Ä—É–π –í–°–ï –¥–µ—Ç–∞–ª–∏: –∏–º–µ–Ω–∞, –±—Ä–µ–Ω–¥—ã, —Å—É–º–º—ã, –¥–∞—Ç—ã, –ø—Ä–æ—Ü–µ–Ω—Ç—ã
4. –û—Ç–º–µ—á–∞–π –í–°–ï —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∞–∫—Ü–∏–∏
5. –°–≤—è–∑—ã–≤–∞–π –Ω–∞—Ö–æ–¥–∫–∏ —Å —Ü–µ–ª—è–º–∏ –∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏ –±—Ä–∏—Ñ–∞

–°–¢–†–£–ö–¢–£–†–ê –ê–ù–ê–õ–ò–ó–ê:

### –†–ï–°–ü–û–ù–î–ï–ù–¢
[–í–°–Ø –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–µ –∏–∑ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –ë–ï–ó –¥–æ–¥—É–º—ã–≤–∞–Ω–∏—è]

### –ö–õ–Æ–ß–ï–í–´–ï –ü–†–û–ë–õ–ï–ú–´
–î–ª—è –∫–∞–∂–¥–æ–π –ø—Ä–æ–±–ª–µ–º—ã:
- –ü—Ä–æ–±–ª–µ–º–∞: [–¢–û–ß–ù–û–ï –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é]
- –¶–∏—Ç–∞—Ç–∞: "[–ü–û–õ–ù–ê–Ø –î–û–°–õ–û–í–ù–ê–Ø —Ü–∏—Ç–∞—Ç–∞ —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞ –º–∏–Ω–∏–º—É–º 50 —Å–ª–æ–≤]"
- –ö–æ–Ω—Ç–µ–∫—Å—Ç: [–¢–û–ß–ù–´–ï –¥–µ—Ç–∞–ª–∏ —Å–∏—Ç—É–∞—Ü–∏–∏]
- –≠–º–æ—Ü–∏–∏: [–¢–û–õ–¨–ö–û —É–ø–æ–º—è–Ω—É—Ç—ã–µ —ç–º–æ—Ü–∏–∏]
- –ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è: [–¢–û–õ–¨–ö–û —Å–∫–∞–∑–∞–Ω–Ω–æ–µ —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–º]

### –ü–û–¢–†–ï–ë–ù–û–°–¢–ò –ò –ñ–ï–õ–ê–ù–ò–Ø
- –Ø–≤–Ω—ã–µ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏: [–¢–û–õ–¨–ö–û –ø—Ä—è–º–æ —Å–∫–∞–∑–∞–Ω–Ω–æ–µ]
- –ò–¥–µ–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ: [–¢–û–õ–¨–ö–û —Å–ª–æ–≤–∞ —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞]
- –¶–∏—Ç–∞—Ç—ã: "[–ö–∞–∂–¥–∞—è —Ü–∏—Ç–∞—Ç–∞ –ü–û–õ–ù–û–°–¢–¨–Æ]"

### –≠–ú–û–¶–ò–û–ù–ê–õ–¨–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢
- –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–∏–∫–∏: [–¢–û–ß–ù–´–ï –º–æ–º–µ–Ω—Ç—ã —Å —Ü–∏—Ç–∞—Ç–∞–º–∏]
- –ò–∑–º–µ–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è: [–° –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞–º–∏]

–§–†–ê–ì–ú–ï–ù–¢ –ò–ù–¢–ï–†–í–¨–Æ:
{chunk}"""

        response = self._make_api_call(prompt)
        return response
    
    def _analyze_profile_and_themes(self, summary: str, interview_num: int) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—Ñ–∏–ª—è —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞ –∏ –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ–º"""
        context = self.brief_manager.get_brief_context()
        
        prompt = f"""{context}

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–æ—Ñ–∏–ª—å —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞ –∏ –∫–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é ‚Ññ{interview_num}.

–í–µ—Ä–Ω–∏ JSON:
{{
    "respondent_profile": {{
        "demographics": "–¢–û–õ–¨–ö–û —Ç–æ, —á—Ç–æ —è–≤–Ω–æ —Å–∫–∞–∑–∞–Ω–æ –≤ –∏–Ω—Ç–µ—Ä–≤—å—é",
        "occupation": "–¢–û–õ–¨–ö–û –µ—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –ø—Ä–æ—Ñ–µ—Å—Å–∏—è",
        "experience_level": "–¢–û–õ–¨–ö–û —Ä–µ–∞–ª—å–Ω—ã–π –æ–ø—ã—Ç –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é",
        "context": "–¢–û–õ–¨–ö–û —Ä–µ–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é",
        "tech_literacy": "–¢–û–õ–¨–ö–û –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ",
        "motivations": "–¢–û–õ–¨–ö–û —è–≤–Ω—ã–µ –º–æ—Ç–∏–≤–∞—Ü–∏–∏ –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é",
        "lifestyle": "–¢–û–õ–¨–ö–û –µ—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è",
        "archetype": "–ù–∞ –æ—Å–Ω–æ–≤–µ –†–ï–ê–õ–¨–ù–´–• –¥–∞–Ω–Ω—ã—Ö",
        "unique_traits": "–¢–û–õ–¨–ö–û —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —á–µ—Ä—Ç—ã –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é"
    }},
    "key_themes": [
        {{
            "theme": "–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã",
            "description": "–î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–µ–º—ã",
            "frequency": "–°–∫–æ–ª—å–∫–æ —Ä–∞–∑ —É–ø–æ–º–∏–Ω–∞–ª–∞—Å—å",
            "importance": "–í–∞–∂–Ω–æ—Å—Ç—å –¥–ª—è —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞",
            "quotes": ["–ü–û–õ–ù–ê–Ø —Ü–∏—Ç–∞—Ç–∞ –º–∏–Ω–∏–º—É–º 50 —Å–ª–æ–≤"],
            "emotional_tone": "–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ–∫—Ä–∞—Å —Ç–µ–º—ã",
            "relevance_to_brief": "–ö–∞–∫ —Å–≤—è–∑–∞–Ω–æ —Å —Ü–µ–ª—è–º–∏ –±—Ä–∏—Ñ–∞"
        }}
    ]
}}

–°–£–ú–ú–ê–†–ò –ò–ù–¢–ï–†–í–¨–Æ:
{summary[:3000]}"""

        response = self._make_api_call(prompt)
        return self._extract_json(response)
    
    def _analyze_pains_and_needs(self, summary: str, interview_num: int) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –±–æ–ª–µ–π –∏ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π"""
        context = self.brief_manager.get_brief_context()
        
        prompt = f"""{context}

–ù–∞–π–¥–∏ –í–°–ï –±–æ–ª–∏, –ø—Ä–æ–±–ª–µ–º—ã –∏ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞ –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é ‚Ññ{interview_num}.

–í–µ—Ä–Ω–∏ JSON:
{{
    "pain_points": [
        {{
            "pain": "–¢–û–ß–ù–û–ï –æ–ø–∏—Å–∞–Ω–∏–µ –±–æ–ª–∏ –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é",
            "pain_type": "functional/process/emotional/social/financial",
            "root_cause": "–ö–æ—Ä–Ω–µ–≤–∞—è –ø—Ä–∏—á–∏–Ω–∞ –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é",
            "symptoms": ["–°–∏–º–ø—Ç–æ–º –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é"],
            "context": "–¢–û–ß–ù–´–ô –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é",
            "severity": "critical/high/medium/low",
            "frequency": "–¢–û–ß–ù–ê–Ø —á–∞—Å—Ç–æ—Ç–∞ –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é",
            "impact": "–¢–û–ß–ù–û–ï –≤–ª–∏—è–Ω–∏–µ –∏–∑ —Å–ª–æ–≤ —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞",
            "current_solution": "–ß—Ç–æ –¢–û–ß–ù–û –¥–µ–ª–∞–µ—Ç —Å–µ–π—á–∞—Å",
            "ideal_solution": "–ß—Ç–æ –¢–û–ß–ù–û —Ö–æ—á–µ—Ç",
            "quotes": ["–ü–û–õ–ù–ê–Ø —Ü–∏—Ç–∞—Ç–∞ –æ –ø—Ä–æ–±–ª–µ–º–µ –º–∏–Ω–∏–º—É–º 50 —Å–ª–æ–≤"],
            "emotional_impact": "–¢–û–ß–ù–´–ï —ç–º–æ—Ü–∏–∏ –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é",
            "relevance_to_brief": "–ö–∞–∫ —Å–≤—è–∑–∞–Ω–æ —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –±—Ä–∏—Ñ–∞"
        }}
    ],
    "needs": [
        {{
            "need": "–¢–û–ß–ù–ê–Ø —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏",
            "need_type": "functional/emotional/social/self-actualization",
            "job_to_be_done": "–ß—Ç–æ –¢–û–ß–ù–û –ø—ã—Ç–∞–µ—Ç—Å—è —Å–¥–µ–ª–∞—Ç—å",
            "current_satisfaction": "–ù–∞—Å–∫–æ–ª—å–∫–æ —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–∞ –ø–æ —Å–ª–æ–≤–∞–º —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞",
            "importance": "critical/high/medium/low",
            "triggers": ["–¢–û–ß–ù–´–ô —Ç—Ä–∏–≥–≥–µ—Ä –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é"],
            "barriers": ["–¢–û–ß–ù–´–ô –±–∞—Ä—å–µ—Ä –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é"],
            "success_criteria": "–ß—Ç–æ –±—É–¥–µ—Ç —É—Å–ø–µ—Ö–æ–º –ø–æ —Å–ª–æ–≤–∞–º —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞",
            "quotes": ["–ü–û–õ–ù–ê–Ø —Ü–∏—Ç–∞—Ç–∞ –æ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –º–∏–Ω–∏–º—É–º 50 —Å–ª–æ–≤"],
            "related_pains": ["–°–≤—è–∑–∞–Ω–Ω—ã–µ –±–æ–ª–∏"],
            "relevance_to_brief": "–ö–∞–∫ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –±—Ä–∏—Ñ–∞"
        }}
    ]
}}

–°–£–ú–ú–ê–†–ò:
{summary[:3000]}"""

        response = self._make_api_call(prompt)
        return self._extract_json(response)
    
    def _analyze_emotions_and_insights(self, summary: str, interview_num: int) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π –∏ –∏–Ω—Å–∞–π—Ç–æ–≤"""
        context = self.brief_manager.get_brief_context()
        
        prompt = f"""{context}

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ–ø—ã—Ç —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞ –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é ‚Ññ{interview_num}.

–í–µ—Ä–Ω–∏ JSON:
{{
    "emotional_journey": [
        {{
            "moment": "–¢–û–ß–ù–û–ï –æ–ø–∏—Å–∞–Ω–∏–µ –º–æ–º–µ–Ω—Ç–∞ –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é",
            "trigger": "–ß—Ç–æ –¢–û–ß–ù–û –≤—ã–∑–≤–∞–ª–æ —ç–º–æ—Ü–∏—é",
            "emotion": "–¢–û–ß–ù–û–ï –Ω–∞–∑–≤–∞–Ω–∏–µ —ç–º–æ—Ü–∏–∏ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞",
            "emotion_family": "primary/secondary/social/cognitive",
            "intensity": 8,
            "valence": "positive/negative/mixed",
            "duration": "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –µ—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è",
            "body_language": "–¢–û–õ–¨–ö–û –µ—Å–ª–∏ –æ–ø–∏—Å–∞–Ω–æ –≤ –∏–Ω—Ç–µ—Ä–≤—å—é",
            "quote": "–ü–û–õ–ù–ê–Ø —Ü–∏—Ç–∞—Ç–∞ –º–∏–Ω–∏–º—É–º 50 —Å–ª–æ–≤",
            "coping": "–ö–∞–∫ —Å–ø—Ä–∞–≤–ª—è–ª—Å—è –ü–û –°–õ–û–í–ê–ú —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞",
            "impact": "–í–ª–∏—è–Ω–∏–µ –ü–û –°–õ–û–í–ê–ú —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞",
            "underlying_need": "–ü–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞",
            "relevance_to_brief": "–°–≤—è–∑—å —Å —Ü–µ–ª—è–º–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"
        }}
    ],
    "insights": [
        {{
            "insight": "–ò–Ω—Å–∞–π—Ç –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –¥–∞–Ω–Ω—ã—Ö (–º–∏–Ω–∏–º—É–º 50 —Å–ª–æ–≤)",
            "insight_type": "behavioral/emotional/cognitive/motivational",
            "confidence": "high/medium/low",
            "evidence": ["–¢–û–ß–ù–û–ï –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é"],
            "contradiction": "–ü—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–µ –µ—Å–ª–∏ –µ—Å—Ç—å",
            "hidden_motivation": "–°–∫—Ä—ã—Ç–∞—è –º–æ—Ç–∏–≤–∞—Ü–∏—è –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞",
            "design_opportunity": "–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–ª—è –¥–∏–∑–∞–π–Ω–∞",
            "business_impact": "–í–ª–∏—è–Ω–∏–µ –Ω–∞ –±–∏–∑–Ω–µ—Å",
            "quotes": ["–ü–û–õ–ù–ê–Ø –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—â–∞—è —Ü–∏—Ç–∞—Ç–∞ –º–∏–Ω–∏–º—É–º 50 —Å–ª–æ–≤"],
            "relevance_to_brief": "–ö–∞–∫ –ø–æ–º–æ–≥–∞–µ—Ç –¥–æ—Å—Ç–∏—á—å —Ü–µ–ª–µ–π –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"
        }}
    ],
    "sentiment_score": 0.5
}}

–°–£–ú–ú–ê–†–ò:
{summary[:3000]}"""

        response = self._make_api_call(prompt)
        return self._extract_json(response)
    
    def _analyze_quotes_and_contradictions(self, summary: str, interview_num: int) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω—ã—Ö —Ü–∏—Ç–∞—Ç –∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π"""
        context = self.brief_manager.get_brief_context()
        
        prompt = f"""{context}

–ù–∞–π–¥–∏ —Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ —Ü–∏—Ç–∞—Ç—ã –∏ –í–°–ï –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –≤ –∏–Ω—Ç–µ—Ä–≤—å—é ‚Ññ{interview_num}.

–í–µ—Ä–Ω–∏ JSON:
{{
    "quotes": [
        {{
            "text": "–ü–û–õ–ù–ê–Ø –î–û–°–õ–û–í–ù–ê–Ø —Ü–∏—Ç–∞—Ç–∞ —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞ (–º–∏–Ω–∏–º—É–º 50 —Å–ª–æ–≤)",
            "context": "–î–µ—Ç–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏—è",
            "significance": "–ü–æ—á–µ–º—É —ç—Ç–∞ —Ü–∏—Ç–∞—Ç–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–∞ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
            "reveals": {{
                "about_user": "–ß—Ç–æ –¢–û–ß–ù–û —Ä–∞—Å–∫—Ä—ã–≤–∞–µ—Ç –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ",
                "about_product": "–ß—Ç–æ –¢–û–ß–ù–û –≥–æ–≤–æ—Ä–∏—Ç –æ –ø—Ä–æ–¥—É–∫—Ç–µ",
                "about_market": "–ß—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ —Ä—ã–Ω–∫–µ"
            }},
            "emotions": ["–≠–º–æ—Ü–∏—è –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"],
            "keywords": ["–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –∏–∑ —Ü–∏—Ç–∞—Ç—ã"],
            "quote_type": "pain/need/insight/emotion/solution",
            "relevance_to_questions": "–ö –∫–∞–∫–∏–º –≤–æ–ø—Ä–æ—Å–∞–º –±—Ä–∏—Ñ–∞ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è"
        }}
    ],
    "contradictions": [
        {{
            "contradiction_type": "logical/emotional/behavioral/temporal/value",
            "severity": "high/medium/low",
            "statement_1": {{
                "text": "–¢–û–ß–ù–û–ï –ø–µ—Ä–≤–æ–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ",
                "context": "–ö–æ–Ω—Ç–µ–∫—Å—Ç —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è"
            }},
            "statement_2": {{
                "text": "–¢–û–ß–ù–û–ï –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∞—â–µ–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ",
                "context": "–ö–æ–Ω—Ç–µ–∫—Å—Ç"
            }},
            "analysis": {{
                "nature": "–í —á–µ–º –¢–û–ß–ù–û —Å—É—Ç—å –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è",
                "possible_reasons": ["–í–æ–∑–º–æ–∂–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"]
            }},
            "full_quotes": ["–ü–æ–ª–Ω–∞—è —Ü–∏—Ç–∞—Ç–∞ —Å –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–µ–º 1", "–ü–æ–ª–Ω–∞—è —Ü–∏—Ç–∞—Ç–∞ 2"]
        }}
    ]
}}

–°–£–ú–ú–ê–†–ò:
{summary[:3000]}"""

        response = self._make_api_call(prompt)
        return self._extract_json(response)
    
    def _analyze_business_aspects(self, summary: str, interview_num: int) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –±–∏–∑–Ω–µ—Å-–∞—Å–ø–µ–∫—Ç–æ–≤ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π"""
        context = self.brief_manager.get_brief_context()
        
        prompt = f"""{context}

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –±–∏–∑–Ω–µ—Å-–≤–ª–∏—è–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é ‚Ññ{interview_num} –∏ –Ω–∞–π–¥–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —Ä–æ—Å—Ç–∞.

–í–µ—Ä–Ω–∏ JSON:
{{
    "business_pains": [
        {{
            "pain": "–ë–∏–∑–Ω–µ—Å-–ø—Ä–æ–±–ª–µ–º–∞ –∏–∑ –¥–∞–Ω–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤—å—é",
            "source": "–¢–û–ß–ù–ê–Ø –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è –ø—Ä–æ–±–ª–µ–º–∞-–∏—Å—Ç–æ—á–Ω–∏–∫",
            "impact": {{
                "revenue": "–í–ª–∏—è–Ω–∏–µ –µ—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è",
                "costs": "–í–ª–∏—è–Ω–∏–µ –µ—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è",
                "efficiency": "–í–ª–∏—è–Ω–∏–µ –µ—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è"
            }},
            "urgency": "critical/high/medium/low",
            "quotes": ["–ü–û–õ–ù–ê–Ø –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—â–∞—è —Ü–∏—Ç–∞—Ç–∞ –º–∏–Ω–∏–º—É–º 50 —Å–ª–æ–≤"]
        }}
    ],
    "user_problems": [
        {{
            "problem": "–¢–û–ß–ù–ê–Ø –ø—Ä–æ–±–ª–µ–º–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è",
            "frequency": "–¢–û–ß–ù–ê–Ø —á–∞—Å—Ç–æ—Ç–∞ –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é",
            "severity": "blocker/major/minor",
            "workaround": "–¢–û–ß–ù–û–ï —Ç–µ–∫—É—â–µ–µ —Ä–µ—à–µ–Ω–∏–µ",
            "quotes": ["–ü–û–õ–ù–ê–Ø —Ü–∏—Ç–∞—Ç–∞ –æ –ø—Ä–æ–±–ª–µ–º–µ –º–∏–Ω–∏–º—É–º 50 —Å–ª–æ–≤"]
        }}
    ],
    "opportunities": [
        {{
            "opportunity": "–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –û–°–ù–û–í–ê–ù–ù–ê–Ø –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤—å—é",
            "opportunity_type": "quick_win/strategic/innovation/optimization",
            "based_on_problems": ["–ü—Ä–æ–±–ª–µ–º–∞ –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é"],
            "value_proposition": "–¶–µ–Ω–Ω–æ—Å—Ç—å –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–Ω—Ç–µ—Ä–≤—å—é",
            "quotes": ["–ü–û–õ–ù–ê–Ø –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∞—è —Ü–∏—Ç–∞—Ç–∞ –º–∏–Ω–∏–º—É–º 50 —Å–ª–æ–≤"]
        }}
    ]
}}

–°–£–ú–ú–ê–†–ò:
{summary[:3000]}"""

        response = self._make_api_call(prompt)
        return self._extract_json(response)
    
    def _analyze_brief_related_content(self, summary: str, interview_num: int) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å–≤—è–∑–∞–Ω–Ω–æ–≥–æ —Å –±—Ä–∏—Ñ–æ–º"""
        context = self.brief_manager.get_brief_context()
        questions = self.brief_manager.get_questions_for_analysis()
        goals = self.brief_manager.get_goals_for_analysis()
        
        prompt = f"""{context}

–ù–∞–π–¥–∏ –≤ –∏–Ω—Ç–µ—Ä–≤—å—é ‚Ññ{interview_num} –í–°–ï —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∏ –¥–∞–Ω–Ω—ã–µ, –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ —Ü–µ–ª—è–º –∏ –≤–æ–ø—Ä–æ—Å–∞–º –±—Ä–∏—Ñ–∞.

–¶–ï–õ–ò –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø:
{json.dumps(goals, ensure_ascii=False)}

–í–û–ü–†–û–°–´ –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø:
{json.dumps(questions, ensure_ascii=False)}

–í–µ—Ä–Ω–∏ JSON:
{{
    "goal_related_findings": [
        {{
            "goal": "–¶–µ–ª—å –∏–∑ –±—Ä–∏—Ñ–∞",
            "findings": [
                {{
                    "finding": "–ß—Ç–æ –Ω–∞–π–¥–µ–Ω–æ –≤ –∏–Ω—Ç–µ—Ä–≤—å—é",
                    "quote": "–ü–û–õ–ù–ê–Ø —Ü–∏—Ç–∞—Ç–∞ –º–∏–Ω–∏–º—É–º 50 —Å–ª–æ–≤",
                    "relevance": "–ö–∞–∫ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Ü–µ–ª–∏"
                }}
            ]
        }}
    ],
    "question_related_findings": [
        {{
            "question": "–í–æ–ø—Ä–æ—Å –∏–∑ –±—Ä–∏—Ñ–∞",
            "answers": [
                {{
                    "answer": "–û—Ç–≤–µ—Ç –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é",
                    "quote": "–ü–û–õ–ù–ê–Ø —Ü–∏—Ç–∞—Ç–∞ –º–∏–Ω–∏–º—É–º 50 —Å–ª–æ–≤",
                    "confidence": "high/medium/low"
                }}
            ]
        }}
    ]
}}

–°–£–ú–ú–ê–†–ò:
{summary[:3000]}"""

        response = self._make_api_call(prompt)
        return self._extract_json(response)
    
    def _cross_analyze_interviews(self, summaries: List[InterviewSummary]) -> Dict[str, Any]:
        """–ö—Ä–æ—Å—Å-–∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –∏–Ω—Ç–µ—Ä–≤—å—é"""
        context = self.brief_manager.get_brief_context()
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        analysis_data = {
            'total_interviews': len(summaries),
            'profiles': [s.respondent_profile for s in summaries],
            'all_pains': [pain for s in summaries for pain in s.pain_points or []],
            'all_needs': [need for s in summaries for need in s.needs or []]
        }
        
        prompt = f"""{context}

–ü—Ä–æ–≤–µ–¥–∏ –ì–õ–£–ë–û–ß–ê–ô–®–ò–ô –∫—Ä–æ—Å—Å-–∞–Ω–∞–ª–∏–∑ {len(summaries)} –∏–Ω—Ç–µ—Ä–≤—å—é —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ —Ü–µ–ª–µ–π –±—Ä–∏—Ñ–∞.

–í–µ—Ä–Ω–∏ JSON:
{{
    "common_patterns": [
        {{
            "pattern": "–î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –∏–∑ –¥–∞–Ω–Ω—ã—Ö (–º–∏–Ω. 80 —Å–ª–æ–≤)",
            "pattern_type": "behavioral/emotional/cognitive/social",
            "frequency": "6 –∏–∑ 8 —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤ (75%)",
            "confidence": "high/medium/low",
            "evidence": ["–ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ 1", "–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ 2"],
            "quotes": ["–ü–û–õ–ù–ê–Ø —Ü–∏—Ç–∞—Ç–∞ 1 –º–∏–Ω–∏–º—É–º 60 —Å–ª–æ–≤", "–ü–û–õ–ù–ê–Ø —Ü–∏—Ç–∞—Ç–∞ 2"],
            "underlying_need": "–ì–ª—É–±–∏–Ω–Ω–∞—è –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –∏–∑ –¥–∞–Ω–Ω—ã—Ö",
            "design_implication": "–ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –∏–º–ø–ª–∏–∫–∞—Ü–∏—è",
            "relevance_to_brief": {{
                "goals": ["–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è —Ü–µ–ª—å"],
                "questions": ["–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å"]
            }}
        }}
    ],
    "consensus_points": [
        {{
            "point": "–¢–æ—á–∫–∞ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞ –∏–∑ –¥–∞–Ω–Ω—ã—Ö (50+ —Å–ª–æ–≤)",
            "agreement_level": "100% (8 –∏–∑ 8)",
            "quotes_sample": ["–¶–∏—Ç–∞—Ç–∞ —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞ 1", "–¶–∏—Ç–∞—Ç–∞ —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞ 3"],
            "implication": "–ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∞"
        }}
    ],
    "divergence_points": [
        {{
            "topic": "–¢–µ–º–∞ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –∏–∑ –¥–∞–Ω–Ω—ã—Ö",
            "positions": [
                {{
                    "position": "–ü–æ–∑–∏—Ü–∏—è 1 –∏–∑ –∏–Ω—Ç–µ—Ä–≤—å—é",
                    "holders": [1, 3, 5],
                    "quote": "–•–∞—Ä–∞–∫—Ç–µ—Ä–Ω–∞—è —Ü–∏—Ç–∞—Ç–∞ –º–∏–Ω–∏–º—É–º 60 —Å–ª–æ–≤"
                }}
            ]
        }}
    ]
}}

–î–ê–ù–ù–´–ï –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:
{json.dumps(analysis_data, ensure_ascii=False, indent=2)}"""

        response = self._make_api_call(prompt)
        return self._extract_json(response)
    
    def _generate_final_findings(self, summaries: List[InterviewSummary], cross_analysis: Dict) -> ResearchFindings:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –≤—ã–≤–æ–¥–æ–≤"""
        context = self.brief_manager.get_brief_context()
        
        prompt = f"""{context}

–°–∏–Ω—Ç–µ–∑–∏—Ä—É–π –í–°–ï –¥–∞–Ω–Ω—ã–µ –≤ actionable –≤—ã–≤–æ–¥—ã –¥–ª—è C-level.

–í–µ—Ä–Ω–∏ JSON:
{{
    "executive_summary": "–ò—Å—á–µ—Ä–ø—ã–≤–∞—é—â–µ–µ —Ä–µ–∑—é–º–µ (300-400 —Å–ª–æ–≤). –ù–∞—á–Ω–∏ —Å –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –≥–ª–∞–≤–Ω–æ–π —Ü–µ–ª–∏ –±—Ä–∏—Ñ–∞, –∑–∞—Ç–µ–º –∫–ª—é—á–µ–≤—ã–µ –Ω–∞—Ö–æ–¥–∫–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –≤–æ–ø—Ä–æ—Å—É —Å —Ç–æ—á–Ω—ã–º–∏ —á–∏—Å–ª–∞–º–∏, –∑–∞–∫–æ–Ω—á–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º–∏ –¥–µ–π—Å—Ç–≤–∏—è–º–∏.",

    "key_insights": [
        {{
            "insight_id": "KI001",
            "problem_title": "–ö—Ä–∞—Ç–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã",
            "problem_statement": "–ö–æ–≥–¥–∞ [—Ç–æ—á–Ω–∞—è —Å–∏—Ç—É–∞—Ü–∏—è], –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ [—Ç–æ—á–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞], —á—Ç–æ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ [—Ç–æ—á–Ω–æ–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏–µ]",
            "problem_description": "–ò—Å—á–µ—Ä–ø—ã–≤–∞—é—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö (–º–∏–Ω. 200 —Å–ª–æ–≤)",
            "severity": "critical/high/medium",
            "affected_percentage": "75% (6 –∏–∑ 8)",
            "business_impact": {{
                "metric": "–ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞",
                "current_impact": "–¢–æ—á–Ω—ã–µ —Ç–µ–∫—É—â–∏–µ –ø–æ—Ç–µ—Ä–∏",
                "potential_impact": "–¢–æ—á–Ω—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ä–æ—Å—Ç–∞"
            }},
            "root_cause": "–ì–ª—É–±–∏–Ω–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞",
            "evidence": ["–ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ 1", "–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ 2"],
            "quotes": [
                {{
                    "text": "–ü–û–õ–ù–ê–Ø —Ü–∏—Ç–∞—Ç–∞ (80+ —Å–ª–æ–≤)",
                    "interview_id": 1,
                    "context": "–ö–æ–Ω—Ç–µ–∫—Å—Ç —Ü–∏—Ç–∞—Ç—ã"
                }}
            ],
            "opportunity": {{
                "description": "–î–µ—Ç–∞–ª—å–Ω–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏–∑ –¥–∞–Ω–Ω—ã—Ö (120+ —Å–ª–æ–≤)",
                "value_prop": "–ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ —Ü–µ–Ω–Ω–æ—Å—Ç–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ"
            }},
            "relevance_to_brief": {{
                "addresses_goal": "–ö–∞–∫—É—é —Ü–µ–ª—å –ø–æ–º–æ–≥–∞–µ—Ç –¥–æ—Å—Ç–∏—á—å",
                "answers_question": "–ù–∞ –∫–∞–∫–æ–π –≤–æ–ø—Ä–æ—Å –æ—Ç–≤–µ—á–∞–µ—Ç"
            }},
            "priority": "P0/P1/P2",
            "effort": "S/M/L/XL"
        }}
    ],

    "strategic_recommendations": [
        {{
            "recommendation": "–ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è",
            "rationale": "–î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö",
            "expected_outcome": "–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç",
            "timeline": "–¢–æ—á–Ω—ã–µ —Å—Ä–æ–∫–∏",
            "success_metrics": ["–ú–µ—Ç—Ä–∏–∫–∞ 1", "–ú–µ—Ç—Ä–∏–∫–∞ 2"]
        }}
    ]
}}

–ö–†–û–°–°-–ê–ù–ê–õ–ò–ó:
{json.dumps(cross_analysis, ensure_ascii=False, indent=2)}"""

        response = self._make_api_call(prompt)
        findings_data = self._extract_json(response)
        
        return ResearchFindings(
            executive_summary=findings_data.get('executive_summary', ''),
            key_insights=findings_data.get('key_insights', []),
            behavioral_patterns=cross_analysis.get('common_patterns', []),
            user_segments=[],
            pain_points_map={},
            opportunities=findings_data.get('strategic_recommendations', []),
            recommendations=findings_data.get('strategic_recommendations', []),
            risks=[],
            personas=[]
        )
    
    def _make_api_call(self, prompt: str) -> str:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ API –≤—ã–∑–æ–≤–∞ —Å –ø–æ–¥—Å—á–µ—Ç–æ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        try:
            response = self.client.generate_content(prompt)
            self.api_calls += 1
            
            # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
            estimated_tokens = len(prompt.split()) * 1.3 + len(response.split()) * 1.3
            cost_estimate = self.client.estimate_cost(
                int(estimated_tokens * 0.7),  # –ü—Ä–∏–º–µ—Ä–Ω–æ 70% - –≤–≤–æ–¥
                int(estimated_tokens * 0.3)   # –ü—Ä–∏–º–µ—Ä–Ω–æ 30% - –≤—ã–≤–æ–¥
            )
            self.total_cost += cost_estimate['total_cost']
            
            return response
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ API –≤—ã–∑–æ–≤–∞: {e}")
            return "{}"
    
    def _extract_json(self, text: str) -> Union[Dict, List]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ API"""
        try:
            # –ü–æ–ø—ã—Ç–∫–∞ 1: –≤–µ—Å—å –æ—Ç–≤–µ—Ç - JSON
            try:
                return json.loads(text)
            except:
                pass
            
            # –ü–æ–ø—ã—Ç–∫–∞ 2: JSON –º–µ–∂–¥—É ```json –∏ ```
            json_match = re.search(r'```json\s*(.*?)\s*```', text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(1))
            
            # –ü–æ–ø—ã—Ç–∫–∞ 3: JSON –º–µ–∂–¥—É { –∏ }
            json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(0))
            
            # –ü–æ–ø—ã—Ç–∫–∞ 4: JSON –º–∞—Å—Å–∏–≤ –º–µ–∂–¥—É [ –∏ ]
            json_match = re.search(r'\[[^\[\]]*(?:\[[^\[\]]*\][^\[\]]*)*\]', text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(0))
            
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞. –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤: {text[:200]}")
            return {}
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ JSON: {e}")
            return {}
